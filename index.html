
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" type="text/css" />
<title>Quanqi Hu's Homepage</title>
</head>
<style>
.one{ width:960px; margin:0 auto;}
</style>
<body>
<div class="one">
<div id="toptitle">
</div>
</br>
</br>
<table class="imgtable"><tr><td>
<img src="quanqi.jpeg" width="180" />&nbsp;</td>
<td align="left"><p style="font-size:25px;"><b>Quanqi Hu / 胡筌淇</b><br /></p>
<p>PhD Student<br />
<a href="https://engineering.tamu.edu/cse/index.html">Department of Computer Science & Engineering</a><br />
<a href="https://www.tamu.edu/">Texas A&M University</a><br />
College Station, TX 77843<br />
quanqi-hu [at] tamu.edu</br>
<!--<a href="https://github.com/qiqi-helloworld/"> github</a></br>-->
<a href = 'https://scholar.google.com/citations?user=AGEYvcAAAAAJ&hl=en'> google scholar </a> </br>
<a href = 'https://www.linkedin.com/in/quanqi-hu-80b840145/'> LinkedIn </a> </br>
</td></tr></table>
<p> I am a PhD student at Texas A&M University. My advisor is <a href="http://people.tamu.edu/~tianbao-yang/">Dr. Tianbao Yang</a>. Before transferring to Texas A&M, I spent three years in the Applied Mathematical and Computational Sciences program at University of Iowa as a PhD student and recieved my master's degree in mathematics. I recieved my bachelor's degree in mathematics from the Pennsylvania State University.
<h2>Research Interests</h2>
<p> Optimization for machine learning.


  
<h2>Publications</h2>
<ul><li><b>Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization</b>  <br />
  <b>Quanqi Hu</b>, Dixian Zhu, Tianbao Yang. <br />
To appear in Conference on Neural Information Processing Systems (NeurIPS), 2023.</li></ul>
<ul><li><b>Blockwise Stochastic Variance-Reduced Methods with Parallel Speedup for Multi-Block Bilevel Optimization</b> <a href="https://arxiv.org/abs/2305.18730">[Preprints]</a> <br />
  <b>Quanqi Hu</b>, Zi-Hao Qiu, Zhishuai Guo, Lijun Zhang, Tianbao Yang. <br />
In International Conference on Machine Learning (ICML), 2023.</li></ul>
<ul><li><b>Not All Semantics are Created Equal: Contrastive Self-supervised Learning with Automatic Temperature Individualization</b> <a href="https://arxiv.org/abs/2305.11965">[Preprints]</a><br />
  Zi-Hao Qiu, <b>Quanqi Hu</b>, Zhuoning Yuan, Denny Zhou, Lijun Zhang, Tianbao Yang. <br />
In International Conference on Machine Learning (ICML), 2023.</li></ul>
<ul><li><b>Multi-block Min-max Bilevel Optimization with Applications in Multi-task Deep AUC Maximization</b> <a href="https://arxiv.org/abs/2206.00260">[Preprints]</a><br />
  <b>Quanqi Hu</b>, Yongjian Zhong, Tianbao Yang. <br />
In Conference on Neural Information Processing Systems (NeurIPS), 2022.</li></ul>
<ul><li><b>Large-scale Stochastic Optimization of NDCG Surrogates for Deep Learning with Provable Convergence</b> <a href="https://arxiv.org/abs/2202.12183">[Preprints]</a><br />
  Zi-Hao Qiu*, <b>Quanqi Hu</b>*, Yongjian Zhong, Lijun Zhang, Tianbao Yang. <br />
In International Conference on Machine Learning (ICML), 2022. </li></ul>
<ul><li><b>A Stochastic Momentum Method for Min-max Bilevel Optimization</b> <a href="https://opt-ml.org/papers/2021/paper40.pdf">[PDF]</a><br />
  <b>Quanqi Hu</b>, Bokun Wang, Tianbao Yang. <br />
In NeurIPS Workshop on Optimization for Machine Learning (OPT), 2021. </li></ul>

  * Denotes Equal Contribution.</li></ul>


<h2>Preprints</h2>
<ul><li><b>Randomized Stochastic Variance-Reduced Methods for Multi-Task Stochastic Bilevel Optimization</b> <a href="https://arxiv.org/abs/2105.02266">[Preprints]</a><br />
  Zhishuai Guo, <b>Quanqi Hu</b>, Lijun Zhang, Tianbao Yang. <br /></li></ul>


<h2>Experience</h2>
<ul><li><b>Research Scientist Intern, KLA, Milpitas, CA    May 2023 - Aug. 2023</b>  
<br>
"- Improved the defect detection performance on SEM images."
<br>
"- We used self-supervised pretrained Vision Transformer (ViT) as the backbone and Cascade Mask R-CNN as the detector head. We applied Low-Rank Adaptation (LoRA) to further improve the training efficiency."
<ul/><li/>


<h2>Teaching Assistant</h2>
  <ul><li>MATH:1560 Engineer Math II: Multivariable Calculus, University of Iowa, Fall 2021 </li></ul>
  <ul><li>MATH:1260 The Mathematics of Pokemon Go, University of Iowa, Spring 2021 </li></ul>
  <ul><li>MATH:2560 Engineer Math IV: Differential Equations, University of Iowa, Fall 2020 </li></ul>
  <ul><li>MATH:1440 Mathematics for the Biological Sciencess, University of Iowa, Fall 2020 </li></ul>
  <ul><li>MATH:1460 Calculus for the Biological Sciences, University of Iowa, Spring 2020 </li></ul>
  <ul><li>MATH:1380 Calculus and Matrix Algebra for Business, University of Iowa, Spring 2020 </li></ul>
<ul><li>MATH:3800 Elementary Numerical Analysis, University of Iowa, Fall 2019 </li></ul>
<ul><li>MATH:3600 Intro to Ordinary Differential Equations, University of Iowa, Fall 2019  </li></ul>
<h2>Selected Awards</h2>
<ul><li>Travel Award, Conference on Neural Information Processing Systems (NeurIPS), 2022</li></ul>
<ul><li>Travel Award, International Conference on Machine Learning (ICML), 2022</li></ul>
<ul><li>Steven and Sherry McCrystal Award, Penn State, April 2018</li></ul>
<ul><li>Women in Math Scholarship, Penn State, April 2018</li></ul>


<h2>Services</h2>
<ul><li> Conference Reviewer of ICML 2022, NeurIPS 2022. </li></ul>


<div align = "center" style="display:inline-block;width:208px;"><script type="text/javascript" src="//rf.revolvermaps.com/0/0/7.js?i=53i4hcg8xg3&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;sx=0" async="async"></script></div>
  <div id="footer-text">
</div>
</div>
</div>
</body>
</html>


